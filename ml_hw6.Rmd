---
title: "ml_hw6"
author: "Mohammad"
date: "2023-02-27"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(caret)
library(rpart)
library(rpart.plot)
library(pROC)
library(e1071)
library(NHANES)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%")
```


# Goal

To use the NHANES data to predict Diabetes using similar 11 variables. Those are restricted to the following:

* `Age`
* `Race1`
* `Education`
* `HHIncome`
* `Weight`
* `Height`
* `Pulse`
* `Diabetes` 
* `BMI`
* `PhysActive`
* `Smoke100`


## Preprocessing

```{r preprocessing}
set.seed(123)

data(NHANES)

#Check missingness in the data
Amelia::missmap(NHANES)

nhanes <-
    NHANES %>% 
    as_tibble(NHANES) %>% 
    select(Age, Race1, Education, HHIncome, Weight, Height, Pulse, Diabetes, BMI, PhysActive, Smoke100) %>% 
    janitor::clean_names() %>% 
    drop_na()

#Check data structure and balance of the outcome
str(nhanes)
summary(nhanes[, "diabetes"])

#Partition the data
train.index <- 
    nhanes$diabetes %>% 
    createDataPartition(p = 0.7, list = FALSE)

training <- 
    nhanes[train.index, ]

testing <- 
    nhanes[-train.index, ]
```


## Prediction models 

To predict diabetes using the 11 features from NHANES, we will use the following three algorithms to create the models:

### Classification Tree

Best tune for cp = 0.001. Accuracy = 0.7045. age , bmi, and weight are the highest ranked importance variables 

```{r classtree}
set.seed(123)

diabetestree <-
    train(diabetes~ . , data = training, method = "rpart", 
          trControl= trainControl(method = "cv", number = 10, sampling = "down"), 
           preProc = c("center", "scale"), tuneGrid = expand.grid(cp = seq(0.001, 0.3, by = 0.01)))

#Get best tune and results 
diabetestree$bestTune
diabetestree$results

#Plot the tree
rpart.plot(diabetestree$finalModel)

#Variable importance
varImp(diabetestree)

#Obtain accuracy and other metrics
confusionMatrix(diabetestree)
```


### Support Vector Classifier 

Support Vector Machine with a linear classifier

The best tune for C = 1.9, accuracy = 0.7126

```{r svc}
set.seed(123)

#Trainmodel using different values for cost (C)
svm <- 
    train(diabetes ~ ., data  = training, method = "svmLinear",
          trControl = trainControl(method = "cv", number = 10, sampling = "down"), 
          preProcess = c("center", "scale"), tuneGrid = expand.grid(C = seq(0.001, 2, length = 30)))

#Get results
svm$bestTune
svm$results

#Visualize accuracy versus values of C
plot(svm)

#Obtain metrics of accuracy from training
confusionMatrix(svm)

#See information about final model
svm$finalModel
```

### Logistic regression.

Accuracy = 0.7148

```{r glm}
set.seed(123) 

glm <-
    train(diabetes ~., data = training, method = "glm",
          trControl = trainControl("cv", number = 10, sampling = "down"),  family = "binomial",
          preProc = c("center", "scale"))

#Model performance
confusionMatrix(glm)
```


## Model selection and evaluation

The Support Vector Classifier SVC (accuracy = 0.7126) and traditional logistic regression (accuracy = 0.7148) models performed similarly. However, SVC offer a clear margin of separation in the data making it better in classification of observations and more stable which makes it the "optimal" model to predict diabetes in testing data. . Evaluating the SVC model on the testing data yieldss high accuracy =  0.7051, sensitivity = 0.8223, and a little lower specificity = 0.6916
 
 
```{r predictions}
set.seed(123)

#Make predictions in test set
preds <- predict(svm, testing)

#Get evaluation metrics from test set
confusionMatrix(preds, testing$diabetes, positive = "Yes")
```

## Limitations and considerations

Excluding the missing observations from the data reduces model generalizability and real life data representation. Additionally, using SVC models limits the interpretability. These are two analytical limitations. Moreover, when conducting predictions using this model in practice, close attention must be paid to social and cultural context that may have an impact both on making and using diabetes  predictions in different communities. 
