---
title: "ml_hw6"
author: "Mohammad"
date: "2023-02-27"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(caret)
library(rpart)
library(rpart.plot)
library(pROC)
library(e1071)
library(NHANES)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%")
```


Comparison between Classification Trees, SVM and Logistic Regression

The posted article by Yu et al utilized NHANES data from 1999-2004 to predict diabetes and pre-diabetes using Support Vector Machines. You will conduct a similar analysis using data within the NHANES package in R. For this exercise, you will try to predict Diabetes using similar (although not all) variables. The available data is also slightly different, so you likely won't get the same answers.

REMINDER: Look at the frequency of your outcome variable to check for balance

For this assignment, you will:

1. Restrict the NHANES data to the list of 11 variables below. Partition the data into training and testing using a 70/30 split.

"Age", "Race1", "Education", "HHIncome", "Weight", "Height", "Pulse", "Diabetes", "BMI", "PhysActive", "Smoke100"

```{r tidying}
data(NHANES)

nhanes <-
    NHANES %>% 
    as_tibble(NHANES) %>% 
    select(Age, Race1, Education, HHIncome, Weight, Height, Pulse, Diabetes, BMI, PhysActive, Smoke100) %>% 
    janitor::clean_names() %>% 
    drop_na()

 Amelia::missmap(nhanes)
 
 str(nhanes)
 summary(nhanes[, "diabetes"])
```


2. Construct three prediction models to predict diabetes using the 11 features from NHANES. You will use the following three algorithms to create your prediction models:

a) Classification Tree

```{r partitioning}
train.index <- createDataPartition(nhanes$diabetes, p = 0.7, list = FALSE)

training <- nhanes[train.index, ]
testing <- nhanes[-train.index, ]
```


```{r classtree}
set.seed(123)

diabetestree <-
    train(diabetes~ . , data = training, method = "rpart", 
          trControl= trainControl(method = "cv", number = 10, sampling = "down"), 
           preProc = c("center", "scale"), tuneGrid = expand.grid(cp = seq(0.001, 0.3, by = 0.01)))

diabetestree$bestTune
diabetestree$results

#Plot the tree
rpart.plot(diabetestree$finalModel)

#Variable importance
varImp(diabetestree)

#Obtain accuracy and other metrics
confusionMatrix(diabetestree)
```


b) Support Vector Classifier (i.e. Support Vector Machine with a linear classifier)

```{r svc}
set.seed(123)

#Trainmodel using different values for cost (C)
set.seed(123)

svm <- 
    train(diabetes ~ ., data  = training, method = "svmLinear",
          trControl = trainControl(method = "cv", number = 10, sampling = "down", classProbs = T), 
          preProcess = c("center", "scale"), tuneGrid = expand.grid(C = seq(0.001, 2, length = 30)))

svm$bestTune
svm$results

#Visualize accuracy versus values of C
plot(svm)

#Obtain metrics of accuracy from training
confusionMatrix(svm)

#See information about final model
svm$finalModel
```

c) Logistic regression.

```{r glm}

set.seed(123) 

glm <-
    train(diabetes ~., data = training, method = "glm",
          trControl = trainControl("cv", number = 10, sampling = "down"),  family = "binomial",
          preProc = c("center", "scale"))

#Model performance
confusionMatrix(glm)
```

3. You will optimize each model using cross-validation to choose hyperparameters in the training data and then compare performance across models.

4. Select a "optimal" model and calculate final evaluation metrics in the test set.

```{r predictions}

#Make predictions in testset
preds <-predict(svm, testing)

#Get evaluation metrics from test set
confusionMatrix(preds, testing$diabetes, positive = "Yes")

#Create ROC Curve for Analysis
probs <- predict(svm, testing, type = "prob")

#Another potential evaluation: Area under the Reciver Operating Curve (AUROC)
analysis <- roc(response = testing$diabetes, predictor = probs[,2])
plot(1-analysis$specificities,analysis$sensitivities,type="l",
ylab="Sensitivity",xlab="1-Specificity",col="black",lwd=2,
main = "ROC Curve for Heart Disease Classification")
abline(a = 0, b = 1)
```

5. List and describe at least two limitations/considerations of the model generated by this analysis. Limitations can be analytical or they can be considerations that need to be made regarding how the model would be applied in practice.

The data had a lot of missing data which were excluded prior to training the model. This observations are inportant and includig them accounts for a better represnetation of the populations of interest. Additionally, 
